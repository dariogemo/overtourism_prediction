Args in experiment:
Namespace(activation='gelu', batch_size=128, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='data_casa_di_giulietta_train.csv', dec_in=5, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=5, factor=1, features='MS', freq='t', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='DLinear', model_id='data_casa_di_giulietta_train', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='/home/dario/dev/Stage/Code/../main_dataset/count_data_train', seq_len=96, target='count', test_flop=False, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : data_casa_di_giulietta_train_DLinear_custom_ftMS_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 122478
val 17430
test 34953
	iters: 100, epoch: 1 | loss: 0.8071507
	speed: 0.0083s/iter; left time: 78.8182s
	iters: 200, epoch: 1 | loss: 0.5793840
	speed: 0.0043s/iter; left time: 39.8115s
	iters: 300, epoch: 1 | loss: 0.5847555
	speed: 0.0043s/iter; left time: 39.8706s
	iters: 400, epoch: 1 | loss: 0.6761847
	speed: 0.0043s/iter; left time: 39.4981s
	iters: 500, epoch: 1 | loss: 0.6848693
	speed: 0.0044s/iter; left time: 39.9357s
	iters: 600, epoch: 1 | loss: 0.5965046
	speed: 0.0044s/iter; left time: 39.0411s
	iters: 700, epoch: 1 | loss: 0.7031657
	speed: 0.0043s/iter; left time: 38.5127s
	iters: 800, epoch: 1 | loss: 0.6294177
	speed: 0.0043s/iter; left time: 37.7083s
	iters: 900, epoch: 1 | loss: 0.6429577
	speed: 0.0044s/iter; left time: 37.7660s
Epoch: 1 cost time: 4.630721092224121
Epoch: 1, Steps: 956 | Train Loss: 0.6558307 Vali Loss: 0.7687510 Test Loss: 0.7206016
Validation loss decreased (inf --> 0.768751).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6061193
	speed: 0.0357s/iter; left time: 303.9509s
	iters: 200, epoch: 2 | loss: 0.7128882
	speed: 0.0044s/iter; left time: 36.7756s
	iters: 300, epoch: 2 | loss: 0.6146578
	speed: 0.0044s/iter; left time: 36.6750s
	iters: 400, epoch: 2 | loss: 0.6858233
	speed: 0.0044s/iter; left time: 36.2440s
	iters: 500, epoch: 2 | loss: 0.5826494
	speed: 0.0044s/iter; left time: 35.4491s
	iters: 600, epoch: 2 | loss: 0.6219413
	speed: 0.0043s/iter; left time: 34.4016s
	iters: 700, epoch: 2 | loss: 0.6727569
	speed: 0.0044s/iter; left time: 35.1183s
	iters: 800, epoch: 2 | loss: 0.6198602
	speed: 0.0045s/iter; left time: 34.9693s
	iters: 900, epoch: 2 | loss: 0.5516347
	speed: 0.0044s/iter; left time: 34.2398s
Epoch: 2 cost time: 4.69692587852478
Epoch: 2, Steps: 956 | Train Loss: 0.6145204 Vali Loss: 0.7654836 Test Loss: 0.7175096
Validation loss decreased (0.768751 --> 0.765484).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5230049
	speed: 0.0369s/iter; left time: 278.7665s
	iters: 200, epoch: 3 | loss: 0.5615739
	speed: 0.0044s/iter; left time: 32.4486s
	iters: 300, epoch: 3 | loss: 0.5935208
	speed: 0.0046s/iter; left time: 33.6796s
	iters: 400, epoch: 3 | loss: 0.5568218
	speed: 0.0044s/iter; left time: 32.0826s
	iters: 500, epoch: 3 | loss: 0.5288853
	speed: 0.0045s/iter; left time: 31.9743s
	iters: 600, epoch: 3 | loss: 0.6112130
	speed: 0.0045s/iter; left time: 31.7095s
	iters: 700, epoch: 3 | loss: 0.5570377
	speed: 0.0044s/iter; left time: 30.8626s
	iters: 800, epoch: 3 | loss: 0.6719521
	speed: 0.0044s/iter; left time: 30.4657s
	iters: 900, epoch: 3 | loss: 0.6745199
	speed: 0.0044s/iter; left time: 29.5095s
Epoch: 3 cost time: 4.740699529647827
Epoch: 3, Steps: 956 | Train Loss: 0.6130202 Vali Loss: 0.7654104 Test Loss: 0.7173522
Validation loss decreased (0.765484 --> 0.765410).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6779708
	speed: 0.0362s/iter; left time: 238.9531s
	iters: 200, epoch: 4 | loss: 0.6152198
	speed: 0.0044s/iter; left time: 28.4112s
	iters: 300, epoch: 4 | loss: 0.6633288
	speed: 0.0044s/iter; left time: 27.8178s
	iters: 400, epoch: 4 | loss: 0.7230908
	speed: 0.0044s/iter; left time: 27.5040s
	iters: 500, epoch: 4 | loss: 0.6059302
	speed: 0.0045s/iter; left time: 27.6796s
	iters: 600, epoch: 4 | loss: 0.4940863
	speed: 0.0044s/iter; left time: 26.6902s
	iters: 700, epoch: 4 | loss: 0.6523389
	speed: 0.0044s/iter; left time: 26.1820s
	iters: 800, epoch: 4 | loss: 0.6252487
	speed: 0.0044s/iter; left time: 25.8691s
	iters: 900, epoch: 4 | loss: 0.5526266
	speed: 0.0047s/iter; left time: 27.1914s
Epoch: 4 cost time: 4.722097635269165
Epoch: 4, Steps: 956 | Train Loss: 0.6127526 Vali Loss: 0.7652977 Test Loss: 0.7175719
Validation loss decreased (0.765410 --> 0.765298).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5835570
	speed: 0.0361s/iter; left time: 203.7038s
	iters: 200, epoch: 5 | loss: 0.6362393
	speed: 0.0044s/iter; left time: 24.5743s
	iters: 300, epoch: 5 | loss: 0.7246252
	speed: 0.0044s/iter; left time: 24.0591s
	iters: 400, epoch: 5 | loss: 0.6017371
	speed: 0.0044s/iter; left time: 23.7489s
	iters: 500, epoch: 5 | loss: 0.7918805
	speed: 0.0046s/iter; left time: 23.8557s
	iters: 600, epoch: 5 | loss: 0.7144303
	speed: 0.0044s/iter; left time: 22.5899s
	iters: 700, epoch: 5 | loss: 0.5453816
	speed: 0.0044s/iter; left time: 21.9273s
	iters: 800, epoch: 5 | loss: 0.7096592
	speed: 0.0044s/iter; left time: 21.5293s
	iters: 900, epoch: 5 | loss: 0.6942760
	speed: 0.0043s/iter; left time: 20.9356s
Epoch: 5 cost time: 4.688967227935791
Epoch: 5, Steps: 956 | Train Loss: 0.6125295 Vali Loss: 0.7658041 Test Loss: 0.7173899
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5462033
	speed: 0.0369s/iter; left time: 172.8397s
	iters: 200, epoch: 6 | loss: 0.6254141
	speed: 0.0045s/iter; left time: 20.5282s
	iters: 300, epoch: 6 | loss: 0.6313380
	speed: 0.0044s/iter; left time: 19.5960s
	iters: 400, epoch: 6 | loss: 0.6391844
	speed: 0.0044s/iter; left time: 19.1030s
	iters: 500, epoch: 6 | loss: 0.6823057
	speed: 0.0046s/iter; left time: 19.5047s
	iters: 600, epoch: 6 | loss: 0.5648869
	speed: 0.0046s/iter; left time: 19.2028s
	iters: 700, epoch: 6 | loss: 0.6725320
	speed: 0.0049s/iter; left time: 19.9236s
	iters: 800, epoch: 6 | loss: 0.5176592
	speed: 0.0044s/iter; left time: 17.5703s
	iters: 900, epoch: 6 | loss: 0.5097213
	speed: 0.0047s/iter; left time: 18.4203s
Epoch: 6 cost time: 4.886454820632935
Epoch: 6, Steps: 956 | Train Loss: 0.6124015 Vali Loss: 0.7655185 Test Loss: 0.7174222
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6190824
	speed: 0.0362s/iter; left time: 135.0133s
	iters: 200, epoch: 7 | loss: 0.6029122
	speed: 0.0044s/iter; left time: 15.9961s
	iters: 300, epoch: 7 | loss: 0.5994219
	speed: 0.0044s/iter; left time: 15.6234s
	iters: 400, epoch: 7 | loss: 0.6366911
	speed: 0.0043s/iter; left time: 14.6823s
	iters: 500, epoch: 7 | loss: 0.5924262
	speed: 0.0044s/iter; left time: 14.6158s
	iters: 600, epoch: 7 | loss: 0.5203091
	speed: 0.0043s/iter; left time: 13.9712s
	iters: 700, epoch: 7 | loss: 0.5251204
	speed: 0.0045s/iter; left time: 13.9207s
	iters: 800, epoch: 7 | loss: 0.5617875
	speed: 0.0045s/iter; left time: 13.5722s
	iters: 900, epoch: 7 | loss: 0.5833709
	speed: 0.0046s/iter; left time: 13.4087s
Epoch: 7 cost time: 4.6899261474609375
Epoch: 7, Steps: 956 | Train Loss: 0.6123831 Vali Loss: 0.7655799 Test Loss: 0.7173997
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : data_casa_di_giulietta_train_DLinear_custom_ftMS_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 34953
mse:0.7175715565681458, mae:0.4629753530025482, rse:0.7560241222381592, corr:[0.65707684 0.6533983  0.6522195  0.6553053  0.6561736  0.66349435
 0.65781444 0.66334575 0.6625879  0.6640184  0.66734636 0.66639304
 0.667282   0.6711427  0.66961104 0.66970533 0.67021316 0.67002785
 0.668389   0.6701826  0.6679525  0.66799146 0.6688471  0.66846114
 0.66699696 0.66764295 0.66805243 0.6666332  0.6658198  0.6677439
 0.6676977  0.66866034 0.66905546 0.6681919  0.6686385  0.6684883
 0.6681048  0.66770595 0.6666561  0.66668195 0.66590905 0.66568935
 0.6651571  0.6667028  0.6661116  0.66576064 0.66502845 0.66667545
 0.6657332  0.6664031  0.6660912  0.6662732  0.66716576 0.6668078
 0.66737974 0.6672175  0.6679811  0.6683498  0.6693558  0.6690729
 0.66989434 0.6698669  0.66958016 0.6680975  0.67043763 0.6697605
 0.66960204 0.6689601  0.6678152  0.6664721  0.6663096  0.6660577
 0.6652275  0.6655486  0.665607   0.6651094  0.66461194 0.6641882
 0.6640196  0.66345704 0.66371423 0.6627767  0.66351545 0.66427654
 0.665058   0.6634761  0.6644855  0.6649301  0.6660952  0.66777325
 0.66925836 0.67116874 0.67116135 0.6751446  0.67679155 0.67656636]
